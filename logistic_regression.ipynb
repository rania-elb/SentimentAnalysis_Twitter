{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#training set \n",
    "\n",
    "train_data_file_name = \"C:\\Users\\hp\\Documents\\Projects5\\classifiers\\Dataset3.csv\"\n",
    "train_data_df = pd.read_csv(train_data_file_name, header=None, delimiter=\",\")\n",
    "train_data_df.columns = [\"Sentiment\",\"Text\"]\n",
    "\n",
    "#testing set \n",
    "\n",
    "test_data_file_name = \"C:\\Users\\hp\\Documents\\Projects5\\Testdata.csv\"\n",
    "test_data_df = pd.read_csv(test_data_file_name, header=None, delimiter=\"\\n\")\n",
    "test_data_df.columns = [\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(787952, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>or i just worry too much?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                               Text\n",
       "0          0                       is so sad for my APL frie...\n",
       "1          0                     I missed the New Moon trail...\n",
       "2          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "3          0           i think mi bf is cheating on me!!!   ...\n",
       "4          0                  or i just worry too much?        "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>handed in my uniform today . i miss you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hmmmm.... i wonder how she my number @-)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks to all the haters up in my face a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0                            omg its already 7:30 :O\n",
       "1                 Juuuuuuuuuuuuuuuuussssst Chillin!!\n",
       "2        handed in my uniform today . i miss you ...\n",
       "3           hmmmm.... i wonder how she my number @-)\n",
       "4        thanks to all the haters up in my face a..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5000\n",
       "0    5000\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.786099999999999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "np.mean([len(s.split(\" \")) for s in train_data_df.Text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer        \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#######\n",
    "# based on http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # stem\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "######## \n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    stop_words = 'english',\n",
    "    max_features = 550\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_data_features = vectorizer.fit_transform(train_data_df.Text.tolist() + test_data_df.Text.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(797952L, 85L)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data_features_nd = corpus_data_features.toarray()\n",
    "corpus_data_features_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'amp', u'awesom', u'best', u'better', u'bit', u'com', u'come', u'cool', u'd', u'day', u'did', u'don', u'feel', u'final', u'follow', u'friend', u'fun', u'gon', u'good', u'got', u'great', u'guy', u'ha', u'haha', u'happi', u'hey', u'hi', u'home', u'hope', u'http', u'im', u'just', u'know', u'let', u'like', u'll', u'lol', u'look', u'love', u'lt', u'm', u'make', u'morn', u'movi', u'na', u'need', u'new', u'nice', u'night', u'oh', u'onli', u'peopl', u'quot', u'realli', u'right', u's', u'say', u'sleep', u't', u'thank', u'thi', u'thing', u'think', u'time', u'today', u'tomorrow', u'tonight', u'tri', u'tweet', u'twitpic', u'twitter', u'u', u've', u'veri', u'wa', u'wait', u'want', u'watch', u'way', u'week', u'work', u'x', u'yay', u'ye', u'yeah']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26605 amp\n",
      "15101 awesom\n",
      "11334 best\n",
      "12563 better\n",
      "14883 bit\n",
      "35366 com\n",
      "19276 come\n",
      "10750 cool\n",
      "13412 d\n",
      "56396 day\n",
      "12426 did\n",
      "17543 don\n",
      "14514 feel\n",
      "10826 final\n",
      "20285 follow\n",
      "13953 friend\n",
      "18516 fun\n",
      "10845 gon\n",
      "62009 good\n",
      "32174 got\n",
      "25552 great\n",
      "11347 guy\n",
      "16866 ha\n",
      "21729 haha\n",
      "20691 happi\n",
      "13975 hey\n",
      "14558 hi\n",
      "15959 home\n",
      "24594 hope\n",
      "46977 http\n",
      "21178 im\n",
      "63140 just\n",
      "27451 know\n",
      "10926 let\n",
      "40998 like\n",
      "24791 ll\n",
      "36384 lol\n",
      "22036 look\n",
      "61564 love\n",
      "11931 lt\n",
      "62016 m\n",
      "21546 make\n",
      "20216 morn\n",
      "10732 movi\n",
      "16490 na\n",
      "16928 need\n",
      "26943 new\n",
      "17437 nice\n",
      "24590 night\n",
      "17544 oh\n",
      "10623 onli\n",
      "10642 peopl\n",
      "49155 quot\n",
      "18708 realli\n",
      "13036 right\n",
      "99702 s\n",
      "13905 say\n",
      "11476 sleep\n",
      "59902 t\n",
      "51139 thank\n",
      "41994 thi\n",
      "13064 thing\n",
      "24366 think\n",
      "34610 time\n",
      "30336 today\n",
      "14973 tomorrow\n",
      "12734 tonight\n",
      "11818 tri\n",
      "14005 tweet\n",
      "14168 twitpic\n",
      "21571 twitter\n",
      "33216 u\n",
      "12172 ve\n",
      "14014 veri\n",
      "45889 wa\n",
      "18641 wait\n",
      "17274 want\n",
      "25184 watch\n",
      "13094 way\n",
      "12033 week\n",
      "28796 work\n",
      "11096 x\n",
      "10628 yay\n",
      "13021 ye\n",
      "12808 yeah\n"
     ]
    }
   ],
   "source": [
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(corpus_data_features_nd, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "###   A bag-of-words linear classifier\n",
    "#In order to perform logistic regression in Python we use sklearn.linear_model.LogisticRegression. \n",
    "#But first let's split our training data in order to get an evaluation set. \n",
    "#We will use sklearn.cross_validation.train_test_split.\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# remember that corpus_data_features_nd contains all of our original train and test data, so we need to exclude\n",
    "# the unlabeled test entries\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "    corpus_data_features_nd[0:len(train_data_df)], \n",
    "    train_data_df.Sentiment,\n",
    "    train_size=0.85, \n",
    "    random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " y_pred = log_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.81      0.73       763\n",
      "          1       0.75      0.58      0.65       737\n",
      "\n",
      "avg / total       0.71      0.70      0.69      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#the function sklearn.metrics.classification_report calculates several types of (predictive) scores on a classification model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69799999999999995"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 exam shutdown \n",
      "1 @elfia thank you! hope to see u soon comadre! \n",
      "0 @saborKT If you do go with that haircut post pictures. We all deserve to see how hot you'll look \n",
      "1 @bradwilson oh...ice road truckers is awesome btw \n",
      "0 mariah got 3rd in the 100 and 5th in the long jump!! woooo muh-rye-uhh!! \n",
      "1 [Utterli] http://bit.ly/cREjI  Good Morning: Welcome to a &quot;Thankful Thursday&quot;. I hope you got the memo \n",
      "0 @SingleOrigin totally my pleasure \n",
      "1 WOW!! Jaguar Skills megamix up for download, 30 yrs of hip-hop, 538 tracks: http://twurl.nl/2ia1rt cheers @tag \n",
      "0 @wahliaodotcom Actually don't sound like a bad idea to me. Why waste the shots. \n",
      "0 Going to bed now. Goodnight people \n",
      "0 @woodaledesigns No ideea lol...go on www.blacknight.com and take it if you want \n",
      "0 @fitprosarah is there any other way to eat a Hostess!!! \n",
      "0 Okej, Iï¿½m bored... So I write a little  But Iï¿½m really tired and the back of my neck hurts like *****! So I think I should go to bed soon.\n",
      "0 @TheIronPenguin Unbelievable...and did this on purpose   Have two icecreams\n",
      "0 About to have my VERY FIRST WEDDING SHOWER!! Whoo hoo!!! \n"
     ]
    }
   ],
   "source": [
    "#Finally, we can re-train our model with all the training data and use it for sentiment \n",
    "#classification with the original (unlabeled) test set.\n",
    "\n",
    "# train classifier\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=corpus_data_features_nd[0:len(train_data_df)], y=train_data_df.Sentiment)\n",
    "\n",
    "# get predictions\n",
    "test_pred = log_model.predict(corpus_data_features_nd[len(train_data_df):])\n",
    "\n",
    "# sample some of them\n",
    "import random\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "# print text and labels\n",
    "for text, sentiment in zip(test_data_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "conclusion\n",
    "\n",
    "So judge by yourself. Is our classifier doing a good job at all? Considering how small our training data is, \n",
    "first we are getting a decent accuracy in the eval split, and second, when getting a sample of predictions for the test set,\n",
    "most of the tags make sense. It would be great to find a larger training dataset with labels.\n",
    "Doing so we will be able to train a better model and also to have more data\n",
    "to split into train/eval sets and check our model accuracy.\n",
    "\n",
    "In any case, we have used very simple methods here.\n",
    "And mostly using default parameters. There is a lot of space for improvement in both areas.\n",
    "We can fine tune each library parameters and we can also \n",
    "try more sophisticated parameters (e.g. Random Forests are very powerful). \n",
    "Additionally, we can use a different sparsity coefficient when selecting important words.\n",
    "Our models just considered 85 words. We might try increasing \n",
    "this number to take into account more words (or less?) and see how the accuracy changes.\n",
    "\n",
    "Finally, although the purpose of these tutorials is not to \n",
    "find a winer between R and Python but to show that there are just problems to solve \n",
    "and methods that can use with both platforms, we find here some differences.\n",
    "In the case of R for example we have a nice summary function that we can use with the result of training a linear classifier.\n",
    "This summary shows us very important information regarding how significative each feature is (i.e. each word in our case). \n",
    "Also the text analysis process seems more straightforward in R. But Python as usual is \n",
    "more structured and granular, and is easier to adapt to our particular needs by plugging and pipelining \n",
    "different parts of the process.\n",
    "\n",
    "Where to go from here? The next step should be to put one of our models into a data product people can use. \n",
    "For example, we could use the R model we just built to create a web application where we can\n",
    "submit text and get a sentiment classification estimate. For that we could use \n",
    "the Shiny platform, a great way to quickly create and share data products as web applications.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
